#!./system/bin/python
# showlog:
# Support team tool to re-format Corda5 logs into a more easy readable format, program will reformat standard
# corda5 format that come, which is:
#      {POD_NAME_ID} {JSON formatted log fields}
# This is only format program recognises, this also can be modified, or add more templates to help program to recognise
# other formats, until now it only read what is on `standard-format` field. (I will add support for more templates
# later)
# Majority program behaviour can be changed with proper configuration.
#
# Dependencies:
#   Python 3.6 or higher
#   Libraries:
#     - Pyalm : To be able to handle yaml files -- required for configuration
#
# Last modified: 04/05/2023 -- 11:53 am
# Author: Larry Castro
#
#
from __future__ import print_function
import argparse

import datetime
import json
import re
import sys

import yaml
import os

import builtins as __builtin__


def print(*args1, **kwargs):
    """Replacing the actual print command to print with timestamp"""
    # Adding new arguments to the print function signature
    # is probably a bad idea.
    # Instead consider testing if custom argument keywords
    # are present in kwargs

    timestamp = "%s" % datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S')

    if not args:
        return __builtin__.print(*args1, **kwargs)
    else:
        if not args.interactive:
            return __builtin__.print(*args1, **kwargs)
        msg = ""
        if args1:
            for s in args1:
                msg += s + " "
        if kwargs:
            for each_arg in kwargs:
                msg += f"{kwargs[each_arg]} "

        TTKTextEdit_logging_messages.append(f"{timestamp} {msg}")


def config_file():
    """
    Added config file into program to do not have lingering files
    :return:
    """
    global log_config, config

    config = """
# Log field definition
# this file will contain which fields we require attention to.
configuration:
  corda:
    log:
      # Actual format of logs to expect
      expect:
         standard-format: (?P<pod_id>^\[[a-zA-Z0-9-\/]+^\])?\s*(?P<log_line>.*)
      fields:
        - pod_id
        - log_line
  # Define which fields from `log-line`(Actual Corda5 log format) we are interested on
  log-line-fields:
    instant:
      "-Description": Represents timestamp where event occurred
      epochSecond: represent timestamp in seconds
    level:
      "-Description": Specify severity level of message being shown
    message:
      "-Description": Represent message
    thrown:
      "-Description": Represent class that exposed such message, it is a dictionary
      message: user a custom message
      name: Represents actual error being thrown
      extendedStackTrace: Full stacktrace representing the captured error
    contextMap:
      "-Description": It contains information related to actual flow id, and vnode where
        is being executed
      client_id: unique id for flow identification
      flow_id: standard flow Id
      vnode_id: Actual vnode where flow is being executed

  format:
    layout:
      # All fields need to be enclosed between {}
      # if it exists on current line, otherwise will be blank
      # Any subfield can be accessed using `.` example: contextMap.flow_id
      # If no subfield is specified, whole dictionary is posted (ex. {contextMap} will post all fields within it)

      default: '{instant.epochSecond} {level} {message} {contextMap} {thrown} {thread}'
      test1: '{instant.epochSecond} {level} {message} flow_id: {contextMap.flow_id} vnode_id: {contextMap.vnode_id} {thrown.extendedStackTrace} '
      test2: '{instant.epochSecond} {level} {message} flow_id: {contextMap.flow_id} vnode_id: {contextMap.vnode_id} {thrown}'
      test3: '{instant.epochSecond}|{level}|{message} flow_id: {contextMap.flow_id} vnode_id: {contextMap.vnode_id} {thrown}'
    conversions:
      # This will help to convert epochSecond into a readable human format, below line is `python executable` commands
      # Any required library to use conversion exec statement need to be added into `libraries` field, these libraries
      # will be automatically imported *before* executing statement
      # Here you can define variable that will be found in log file, and what conversion will be performed on it

      instant.epochSecond: 
        execute: datetime.datetime.fromtimestamp(instant.epochSecond).strftime('%Y-%m-%d %H:%M:%S')
        libraries:
           - import datetime

      timeMillis: 
      # In this case python only convert seconds timestamps into human readable time stamp, but conversion routine
      # has a condition to determine if value given is milliseconds or seconds and will act accordantly...
      #
        execute: datetime.datetime.fromtimestamp(timeMillis).strftime('%Y-%m-%d %H:%M:%S')
        libraries:
           - import datetime

    # This define which output is being used from `layout` list by default
    default-layout: default       
    """
    try:
        log_config = yaml.safe_load(config)
    except BaseException as be:
        print(f"[{program_name}]: There's an error on default configuration: {be} unable to continue")
        exit(0)


def load_config():
    """
    Load fields of interest list
    :return:
    """
    global log_config

    if os.path.exists(f"./{program_config}"):
        try:
            with open(f"./{program_config}", "r") as rfh:
                log_config = yaml.safe_load(rfh.read())
            print(f"Reading configuration from {program_config}")
        except BaseException as be:
            print(f"{program_name}: I'm sorry but I'm not able to properly read config file ./{program_config} "
                  f"due to {be}")
            exit(0)
    else:
        config_file()

    # define what part of line is actual `log_line` this will help to identify which is the part of line
    # that will need to be analysed -- this is very important to define.

    try:
        if 'expect' in log_config['configuration']['corda']['log']:
            if 'standard-format' in log_config['configuration']['corda']['log']['expect']:
                # print(log_config['configuration']['corda']['log']['expect']['standard-format'])
                regex = re.compile(log_config['configuration']['corda']['log']['expect']['standard-format'])
                # This will indicate which group we are intereste in
                log_config['configuration']['corda']['log']['group'] = regex.groupindex['log_line']
            else:
                print("Unable to analyse give file, as no regular expression has been provided")
                print("You can try using --parse-json option instead if you do not want to modify actual config")
    except BaseException as be:
        print("Program will require you to define what is the actual `log_line` to be able to parse it correctly")
        print("Make sure you add Placeholder for `log_line` into your regex, this is how program identify what to analyse")
        print("It seems actual regex expression is missing `log_line` label for right group, below is actual regex found")
        exit(0)


def read_file(filename):
    """
    Read given file
    :param filename:
    :return:
    """
    wfh = None
    line_counter = 1
    group = log_config['configuration']['corda']['log']['group']
    try:
        with open(filename, "r+") as rfh:

            for each_line in rfh:
                if args.show_line_number:
                    sline_counter = f"{line_counter:>5} "
                else:
                    sline_counter = ""

                if not args.line_detail:
                    result_line = parse(each_line)

                    if each_line == result_line:
                        print(f"{sline_counter}{result_line}", end="")
                    else:
                        print(f"{sline_counter}{result_line}")
                else:
                    parse_line = re.search(log_config['configuration']['corda']['log']['expect']['standard-format'],
                                           each_line)
                    for each_conversion in conversions:
                        if parse_line:
                            try:
                                convert_into_dict = json.loads(parse_line.group(group))
                                test1, test2 = generate_internal_access(convert_into_dict,  each_conversion)
                                if args.run_conversions and (test1 and test2):
                                    variable_access, \
                                        value_to_convert = generate_internal_access(convert_into_dict, each_conversion)
                                    converted_value = check_conversions(each_conversion, value_to_convert)
                                    exec(f'convert_into_dict{variable_access}="{converted_value}"')
                                if args.json_pretty:
                                    try:
                                        if sline_counter:
                                            print(f"==== {sline_counter} ==== ")
                                        pretty(convert_into_dict)
                                    except BaseException as be:
                                        print(f"forced termination")
                                else:
                                    try:
                                        if sline_counter:
                                            print(f"==== {sline_counter} ==== ")
                                        print(json.dumps(convert_into_dict, indent=2))
                                    except BaseException as be:
                                        print(f"forced termination")
                            except json.decoder.JSONDecodeError as je:
                                print(f"{sline_counter} {each_line}", end="")
                line_counter += 1
    except IOError as io:
        print(f"{program_name}: unable to open {filename} due to: {io}")
        exit(1)


def parse(log_line, selected_layout=None):
    """
    Will try to parse given line using loaded configuration settings.
    :param log_line: original line from logs
    :param selected_layout: will use layout selected, otherwise will use default set on config
    :return: a parsed version of this original line
    """
    global log_config
    # Will parse current line to match expected log format
    extract_fields = re.match(rf"{expected_log_format['standard-format']}", log_line)
    # final_output = log_line
    # Analyse desired log format output:
    output_layout = re.findall(r"\{([a-zA-Z_.?-]+)\}", desired_output_format)
    final_output_values = {}
    labels = []
    if extract_fields:
        # Detected a valid line
        # Detect if line message contains a json format
        line_groups = extract_fields.groupdict()
        try:
            log_scan = json.loads(line_groups['log_line'])
        except json.decoder.JSONDecodeError as jsonError:
            # Is not a on Json format, then return same line no further parsing will be performed
            if args.skip_pod_name and extract_fields.group("log_line"):
                return extract_fields.group("log_line")
            else:
                return log_line

        # This will restrict fields that can be shown, I think will be better approach for this tool
        # to allows all fields, and it is up to user to decide what to see.
        #
        # for each_field in fields_of_interest:
        #     # if field of interest exist on current line gather its value
        #     if each_field in log_scan:
        #         line_values[each_field] = log_scan[each_field]

        # This will allow to see al fields found on each line.
        #
        line_values = log_scan
        final_output = ""

        for each_field in output_layout:
            # in the case we are dealing with a dictionary, instead of printing full dictionary as string
            # this will build a variable required to pull sub-values
            # for example 'instant.epochSeconds'  will pull it like log_scan['instant']['epochSeconds']
            if '.' in each_field:
                variables = each_field.split('.')
                final_variable = "log_scan"
                for each_var in variables:
                    final_variable = final_variable + f'["{each_var}"]'

                try:
                    final_variable = eval(final_variable)
                    final_output = final_output + f"{variables[len(variables) - 1]}: {final_variable} "

                    final_output_values[each_field] = final_variable
                except BaseException as be:
                    pass
                    # print(f"Unable to access {final_variable} from this line: {log_line}")

            else:
                if each_field in line_values:
                    if line_values[each_field]:
                        reformat_variable = expand_variable(line_values[each_field])
                        # final_output = final_output + f"{line_values[each_field]} "
                        final_output = final_output + f"{reformat_variable} "
                        if isinstance(line_values[each_field],dict):
                            final_output_values[each_field] = reformat_variable
                        else:
                            final_output_values[each_field] = line_values[each_field]

    final_log_output = desired_output_format
    # This will delete any label corresponding to a field, if field is not found in current line, it will be deleted
    # this is done to be better visibility, for example if you have a layout like:
    # {timestamp} {severity} flow_id: {flow_id} {message}
    # and in current line field "flow_id" is not found, no value will be shown (ie blank) in such case,
    # previous label(if exist) will be also deleted to prevent confusion and save space
    #
    fixed_messages = re.findall(r"([a-zA-Z_:-]{2,} )?\{([a-zA-Z?_.-]+)\}", desired_output_format)

    for each_field in output_layout:
        if each_field in final_output_values:
            # Check for any required conversion on this field.
            #
            if conversions:
                for check_field in conversions:
                    if check_field == each_field:
                        # User require a conversion on this field
                        try:
                            #  we need to replace actual value for this field on convert method
                            #
                            convert_exec = check_conversions(check_field, final_output_values[each_field])
                            # line_to_exec = conversions[check_field].replace(check_field, "%s" % final_output_values[each_field])
                            # #
                            # # Run conversion
                            # convert_exec = eval(line_to_exec)
                            final_output_values[each_field] = convert_exec
                        except BaseException as be:
                            print(f"Unable to convert {each_field} conversion method failed due to : {be}")

            final_log_output = final_log_output.replace('{' + each_field + '}', "%s" % final_output_values[each_field])
        else:
            if fixed_messages:
                for label in fixed_messages:
                    test_label = label[0].strip(' ').strip(':')
                    if test_label and test_label in each_field:
                        final_log_output = final_log_output.replace(label[0], '')

            final_log_output = final_log_output.replace('{' + each_field + '}', '')

    if not final_log_output.strip():
        return log_line

    return final_log_output.strip(" ")

def expand_variable(variable):
    """
    This will print content of a variable that it is a dictionary, content will be printed without any order
    :param variable: actual dictionary variable to print
    :return: a string with all dictionary values on the same line, if variable is not a dictionary will be returned as
    it is.
    """

    rvariable = ""
    # These labels will not be printed, only label, it will still print its content
    no_label = ['message','thread','logger']
    if isinstance(variable,dict):
        for each_value in variable:
            if each_value not in no_label:
                rvariable = rvariable +  f"{each_value}: {variable[each_value]} "
            else:
                rvariable = rvariable + f"{expand(variable[each_value])} "

    if rvariable:
        return rvariable

    return variable


def generate_internal_access(variable_dict, variable_to_get):
    """
    This method will try to generate internal access to given variable
    :type variable_dict: Actual dictionary object to access
    :param variable_to_get: dot representation to reach such variable
    :return: access representation to get into that variable,value of variable asked for
    """

    if '.' in variable_to_get:
        variables = variable_to_get.split('.')
        fvariable = ""
        for each_var in variables:
            fvariable = fvariable + f"['{each_var}']"

        try:
            fvariable_value = eval(f"variable_dict{fvariable}")
            # final_output = final_output + f"{variables[len(variables)-1]}: {final_variable} "
            return fvariable, fvariable_value
        except KeyError as be:

            # print(f"Unable to access variable_dict{fvariable} from this line: {variable_dict}")
            return None, None

    return None


def check_conversions(variable_to_convert, value):
    """
    Check for a valid conversion
    """

    # User require a conversion on this field
    try:
        # Check if giving timestamp value is in the range of Seconds (max length 10) or milliseconds (max lenght 13)
        if len("%s" % value) > 10:
            # if given value represent milliseconds, need to divide them by 1000 to make them seconds
            value = value / 1000
        #  we need to replace actual value for this field on convert method
        #
        line_to_exec = conversions[variable_to_convert]['execute'].replace(variable_to_convert, "%s" % value)
        # Check if there's any required library:
        if 'libraries' in conversions[variable_to_convert]:
            # import given libraries:
            for each_library in conversions[variable_to_convert]['libraries']:
                exec(each_library)
        #
        # Run conversion
        convert_exec = eval(line_to_exec)
        return convert_exec
    except BaseException as be:
        print(f"Unable to convert {variable_to_convert} conversion method failed due to : {be}")
        exit(0)


def conversion(each_field, value):
    """

    :param string_line:
    :return:
    """
    # Check for any required conversion on this field.
    #

    for check_field in conversions:
        if check_field == each_field:
            # User require a conversion on this field
            try:
                #  we need to replace actual value for this field on convert method
                #
                convert_exec = check_conversions(check_field, value)
                return convert_exec
            except BaseException as be:
                print(f"[SHOWLOG ERROR] Unable to convert {each_field} conversion method failed due to : {be}")
                return value

    return value


def create_output(filename):
    """
    Open a new file called filename and will dump all converted lines into it
    :param filename: name of new file
    :return: file handler
    """
    wfh = open(filename, "w+")

    return wfh


def list_layouts():
    """
    Print current supported layouts
    :return:
    """
    print("\nBelow are defined layouts:")
    print("\nLayout name\t Produced output\n")
    for each_layout in layouts:
        print(f"{each_layout:10}: {layouts[each_layout]}")


def pretty(keyvals, indent='  '):
    # ANSI color terminal escape sequences
    OKBLUE = '\033[94m'
    ENDC = '\033[0m'

    print('{')
    for key, val in keyvals.items():
        print('{}  {}"{}"{}: '.format(indent, OKBLUE, key, ENDC), end="")
        if isinstance(val, dict):
            pretty(val, indent + '  ')
        elif isinstance(val, str):
            print('"{}",'.format(val))
        else:
            print('{},'.format(val))
    print(indent + '},')


def list_conversions():
    """
    List defined conversions
    :return:
    """
    print("\nFollowing conversion will be performed on defined variables, if variable is being found associated"
          " conversion will be executed\n")

    print("Variable associated\t\tPython code for conversion")
    print("===================\t\t================================================")
    for each_conversion in conversions:
        print(f"{each_conversion:30}: {conversions[each_conversion]}")

    print("\n\nBe aware program uses `eval` to execute this code, you will need to be sure proper libraries are present"
          " within program context to be able to run this successfully.\n"
          "This default conversion has required libraries present already.")
    print("\nIf want to ignore these conversions, please run with the flag `--ignore-conversions` then original value "
          "will be shown")


def show_config():
    """
    Show current config used
    :return:
    """

    print(yaml.safe_dump(log_config))


def export_default():
    """
    Export default configuration into a file
    :return:
    """
    global config
    with open(f"{program_config}", "w") as wcf:
        wcf.write(config)

    print(f"{program_name}: Configuration file has been exported as {program_config}")


def parse_json(file_to_process=None):
    """
    Try to parse given file using json
    :return:
    """

    if file_to_process:
        parse_file = file_to_process
        used_file = load_index(file_to_process)
    else:
        used_file = load_index(file_to_process)
        parse_file = args.log_file

    # tl = file['total-lines']
    tl = used_file.get('total-lines')
    cpi = 0
    cl = 0
    if not args.fields and not used_file.get('fields'):
        print("Json parsing require an analysis of what are current"
              " fields; attempting to create an index file with this info")
        used_file = generate_field_index(parse_file)

        return used_file

    if not args.fields and used_file.get('fields'):
        if not args.interactive:
            print("Please select desired fields to be shown:")
            print("By using argument '--fields 1,2,3...' and selecting which fields to show")
            for pos, each_field_found in enumerate(used_file.get('fields')):
                print(f"{pos:3} - {each_field_found.strip()}")
        return used_file
    else:
        if used_file.get('file-format') == "JSON per line":
            with open(f"{parse_file}", "r") as lghr:
                for each_line in lghr:
                    print_line(each_line, args.fields, used_file)
                    if args.output:
                        cl += 1
                        cp = (cl * 100) / tl
                        if cp >= cpi:
                            cpi = cpi + 10
                            print("Finished... %.2f%s" % (cp, '%'), file=sys.stderr)
        if used_file.get('file-format') == "JSON File":
            line_count = 0
            with open(f"{parse_file}", "r") as lghr:
                json_file = json.load(lghr)
                for each_record in json_file:
                    # line_count += 1
                    print_line(each_record, args.fields, used_file)

    return used_file


def print_line(line, selected_fields, used_file):
    """
    Print each line -- this is only running on mode `parse-json`
    :param line: original line
    :param selected_fields: desired fields to print
    :return:
    """

    final_line = ""
    selected_name_fields = {}
    to_print = ""
    # line = parse(line)
    #
    if args.fields:
        selected_fields = args.fields.split(",")

    value = None

    try:
        if used_file.get("file-format") == 'JSON per line':
            line_fields = json.loads(line)
        if used_file.get("file-format") == 'JSON File':
            line_fields = line
        for each_field in selected_fields:
            fld = used_file.get('fields')[int(each_field)].strip()
            if fld in line_fields:
                value = line_fields[fld]
            else:
                result = generate_internal_access(line_fields, fld)
                if not result[1]:
                    # print(line)
                    # input("Missing fields!...STOPPING")
                    result = (fld, '')

                if result:
                    value = result[1]

            selected_name_fields[int(each_field)] = fld
            # Verify and execute any conversion required
            #if args.interactive:
            value = conversion(fld, value)

            if value:
                value = expand(value)
                final_line = final_line + f" {value}"

        if final_line:
            to_print = final_line.strip()
        else:
            to_print = line.strip()

        used_file.set('show-fields', selected_name_fields)

    except json.JSONDecodeError as jde:
        to_print = line.strip()

    if not args.interactive:
        print(to_print)
    else:
        return to_print


def expand(value):
    """
    Will force to interpret some special chars
    :param value:
    :return:
    """
    if not value:
        return
    expand_chars = {
        '\\n': '\n',
        '\\"': '"',
        '\\t': '\t'
    }

    for each_char in expand_chars:
        if isinstance(value, str) and each_char in value:
            value = value.replace(each_char, expand_chars[each_char])

    return value


def load_index(file_to_process=None):
    """

    :return:
    """

    used_file = File()
    if file_to_process:
        parse_file = file_to_process
    else:
        parse_file = args.log_file

    if os.path.exists(f"{parse_file}.jidx"):
        if not used_file.get_all_attributes():
            with open(f"{parse_file}.jidx", "r") as lhfidx:
                used_file.set_all_attributes(yaml.safe_load(lhfidx))

    else:
        # if index file is not found, it will be generated automatically
        used_file = generate_field_index(parse_file)
    return used_file


def generate_field_index(file_to_process=None, save=False):
    """
    Will generate a field index for given file, and also will save file with found fields, for future usage.
    :return:
    """

    file = File()
    fields = None
    if file_to_process:
        parse_file = file_to_process
    else:
        parse_file = args.log_file

    file.set_name(parse_file)

    fields_found = None
    tl = 0
    file_format = None
    if not args.fields:
        print("You will need to select which fields you want to see")
    try:
        print("Analysing file, please wait...")

        # Check if is a JSON file
        #
        try:
            with open(parse_file, "r") as lfh:
                json_file = json.load(lfh)
            tl = len(json_file)
            if json_file:
                file_format = "JSON File"
                for each_record in json_file:
                    fields = getKeys(each_record, "", fields_found)
                    fields_found = fields

        except json.JSONDecodeError as jde:
            # Isn't a json file
            # try next test... is a json file per line?
            pass

        if not file_format:
            # Check if json per line file
            #
            with open(parse_file, "r") as lfh:
                for each_line in lfh:
                    tl += 1
                    try:
                        line_fields = json.loads(each_line)
                        if line_fields:
                            fields = getKeys(line_fields, "", fields_found)
                            fields_found = fields
                            if not file_format:
                                file_format = "JSON per line"
                    except json.JSONDecodeError as jde:
                        # read line is not json format
                        pass

                        # print(each_line.strip())
        if fields:
            file.set_name(parse_file)
            file.set("total-lines", tl)
            file.set("fields", fields)
            file.set("file-format", file_format)
        else:
            file.set_name(parse_file)
            file.set("total-lines", tl)
            file.set("fields", None)
            file.set("file-format", "unknown")
            print("I'm not able to identify JSON format on whole file, loading it anyway")

        if save:
            try:
                with open(f"{parse_file}.jidx", "w") as lfhidx:
                    yaml.safe_dump(file.get_all_attributes(), lfhidx)
            except IOError as iow:
                print(f"Unable to write file index {args.log_file}.jidx due to {iow}")
                print("Without this file I'll be not able to extract desired fields, using --parse-json option")

    except IOError as io:
        print(f"Unable to open {parse_file} due to {io}")
    return file


def getKeys(val, old="$", lfields_found=None):

    if isinstance(val, dict):
        for k in val.keys():
            ff = getKeys(val[k], old + "." + str(k), lfields_found)
            lfields_found = ff
    elif isinstance(val, list):
        for i, k in enumerate(val):
            ff = getKeys(k, old + "." + str(i), lfields_found)
            lfields_found = ff
    else:
        # print("{} : {}".format(old, str(val)))
        old = old.lstrip(".")
        if not lfields_found:
            lfields_found = []

        if old not in lfields_found:
            lfields_found.append(old)

    return lfields_found


def list_log_file_fields(used_file):
    """
    List actual found fields.
    :return: fields_found

    """

    if not used_file or used_file and not used_file.get("fields"):
        used_file = load_index()

    print("\n\nFollowing fields were found:")
    for pos, each_field_found in enumerate(used_file.get("fields")):
        print(f"{pos:3} - {each_field_found}")

    return used_file


def setup():
    """
    This is an interactive way to setup program
    :return:
    """

    if os.path.exists("showlog.yaml"):
        print("A configuration file was found")
        print("Loading configuration file")
        print("==========================")
        listofkeys = getKeysx(log_config, [], "")
        config_keys = [
            'configuration.corda.log.expect.standard-format',
            'configuration.format.layout',
            'configuration.format.default-layout'
        ]
        #
        # print("Following is a definition of what should I expect to recognise line from log (Regex format):")
        # print("Actual value:")
        # print(f"{log_config['configuration']['corda']['log']['expect']['standard-format']}")
        # response = input("To keep same press enter, or type in new regex expression below:\n] ")
        # if not response:
        #     print("Keeping default")
        # else:
        #     log_config['configuration']['corda']['log']['expect']['standard-format'] = response

        for i, each_conf in enumerate(config_keys):
            default = generate_internal_access(log_config, each_conf)
            print(f"{each_conf}")
            if default:
                if isinstance(default[1], list):
                    print("Actual values:")
                    for each_item in default[1]:
                        print(f"  - {each_item}")

                    response_yn = input("Yo")
                    response = input(f"Press enter to keep default [{each_item}]:") or each_item
                else:
                    response = input(f"Press enter to keep default [{default[1]}]:") or default[1]


def interactive_work():
    """
    Launch TUI interface
    :return:
    """
    global wordWrap_value, TTKTextEdit_logcontent, loaded_file, TTKTextEdit_logging_messages
    # import TermTk
    # import yaml
    # import textwrap
    import TermTk as ttk
    from TermTk.TTkCore.signal import pyTTkSlot
    # from TermTk import TTkUtil, TTkUiLoader, TTk

    HighlightCode('timestamps', r'[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}', '#00AAAA')
    HighlightCode('level', 'WARN', '#AAAA00')
    HighlightCode('level', 'WARNING', '#AAAA00')
    HighlightCode('level', r'\bINFO ', '#44AA00')
    HighlightCode('level', 'ERROR ', '#FF8800')

    root = ttk.TTk()

    TTkWindow_logs = ttk.TTkWindow(parent=root,
                                   pos=(4, 1), size=(142, 35),
                                   title=ttk.TTkString("Logs reader", ttk.TTkColor.ITALIC),
                                   border=True,
                                   layout=ttk.TTkGridLayout())

    TTkWindow_logging = ttk.TTkWindow(parent=root,
                                      pos=(26, 36),
                                      size=(100, 8),
                                      title=ttk.TTkString("Messages", ttk.TTkColor.ITALIC),
                                      border=True,
                                      layout=ttk.TTkGridLayout())

    TTKTextEdit_logcontent = ttk.TTkTextEdit(parent=TTkWindow_logs, lineNumberStarting=1)
    TTKTextEdit_logging_messages = ttk.TTkTextEdit(parent=TTkWindow_logging)

    @pyTTkSlot()
    def _analyse_file(file_name):
        """
        Attempt to analyse file with default settings to find out if is possible to parse
        :param file_name: to analyse
        :return:
        """
        global loaded_file, current_file
        print("Attempting to check this file using following Regular Expression:")
        print(f"{expected_log_format} which was set as default setup")
        file = File()

        file.set_name(file_name)
        temp_file = file.get_temp_name()
        line_count = 0
        if file.get_path():
            full_name = f"{file.get_path()}/{temp_file}"
        else:
            full_name = file.get_temp_name()
        with open(f"{full_name}", "w") as tmpfile:
            for each_line in TTKTextEdit_logcontent.toRawText().split("\n"):
                parsed_line = parse(str(each_line))
                line_count += 1
                tmpfile.write(f"{parsed_line}\n")

        file.set('total-lines', line_count)
        file.set('export-format', 'C5 built-in config')
        file.set('selected-layout', 'default')
        file.set('export-file', f"export-{file.get('file-name')}")

        TTKTextEdit_logcontent.setText("")

        load_file(full_name, generate_index=False, original_file_info=file.get_all_attributes())
        loaded_file = file.get_name()
        TTkWindow_logs.setTitle(ttk.TTkString(f"Logs reader -- [{file.get('file-name')}]", ttk.TTkColor.ITALIC))
        file.remove_temp_file()
        current_file = file
        return file

    @pyTTkSlot()
    def load_file(file, generate_index=True, original_file_info=None):
        """
        Load given file
        :return:
        """
        global loaded_file, filepicker_config
        TTKTextEdit_logcontent.setText("")
        with open(file, 'r') as logfile:
            full_file = logfile.read()
            pd = os.path.dirname(file)
            filepicker_config['path'] = pd
            # If I do not require to generate an index for this loading file, it is possible file given
            # is a temporary file view, and it doesn't have a proper format to gather fields.
            if generate_index:
                used_file = load_index(file)
            else:
                if isinstance(original_file_info, dict):
                    used_file = File()
                    used_file.set_all_attributes(original_file_info)
                else:
                    used_file = original_file_info

            if pd:
                used_file.set('file-path', pd)
                loaded_file = f"{pd}/{used_file.get_name()}"
            else:
                loaded_file = used_file.get_name()

            if not used_file:
                print(level="ERROR", message=f"Unable to open index file for {loaded_file}")
                return None

            # Check if file can be loaded (depending on number of lines it has)
            if max_lines_to_read and used_file.get("total-lines") >= max_lines_to_read:
                print(f"This file has more than {max_lines_to_read}, this tool will only load this amount of lines")
                line_count = 0
                for each_line in full_file.split("\n"):
                    TTKTextEdit_logcontent.append(HighlightCode.highlight(ttk.TTkString(each_line)))
                    line_count += 1
                    if line_count >= max_lines_to_read:
                        break
            else:
                TTKTextEdit_logcontent.setText(HighlightCode.highlight(ttk.TTkString(full_file)))

        TTkWindow_logs.setTitle(ttk.TTkString(f"Logs reader -- [{used_file.get_name()}]", ttk.TTkColor.ITALIC))

        # if isinstance(used_file, File):
        #     used_file.set_name(file)
        # else:
        #     pt = os.path.dirname(file)
        #     pf = os.path.basename(file)
        #     if pt:
        #         used_file['file-path'] = pt
        #     used_file['file-name'] = pf

        transformMenu.setEnabled(True)
        viewMenu.setEnabled(True)
        return used_file

    def _close():
        """
        Close actual loaded file
        :return:
        """
        TTKTextEdit_logcontent.setText("")
        transformMenu.setEnabled(False)
        viewMenu.setEnabled(False)
        TTkWindow_logs.setTitle(ttk.TTkString(f"Logs reader", ttk.TTkColor.ITALIC))

    def _line_number():
        """

        :return:
        """
        global line_number

        line_number ^= True
        TTKTextEdit_logcontent.setLineNumber(line_number)
        if line_number:
            lineNumber_option.setText("Line number-[Disable]")
        else:
            lineNumber_option.setText("Line number-[Enable]")

    @pyTTkSlot()
    def _resize_log_content(h, w):
        """
        Try to keep size of parent window...
        :param h: parent window h
        :param w: parent window w
        :return:
        """

        TTKTextEdit_logcontent.resize(h-4, w-4)

    def _show_file_dialog():
        """

        :return:
        """
        global filepicker_config
        filePicker = ttk.TTkFileDialogPicker(pos=(1, 1), size=filepicker_config['size'], caption="Select a file",
                                             path=filepicker_config['path'],
                                             fileMode=ttk.TTkK.FileMode.AnyFile,
                                             filter="All Files (*);;logs files (*.log)")

        ttk.TTkHelper.overlay(TTkWindow_logs, filePicker, 4, 8, True)
        filePicker.pathPicked.connect(load_file)

    def _exit():
        """
        Exit app
        :return:
        """
        TTkWindow_logs.close()
        root.quit()

    @pyTTkSlot()
    def _word_wrap_menu(selection):
        """
        Will setup word wrap for editor
        :param selection: selection to be done
        :return: void
        """

        def _set_wrap():
            """

            :return:
            """
            global wordWrap_value
            TTKTextEdit_logcontent.setWrapWidth(width_value.value())
            TTKTextEdit_logcontent.setLineWrapMode(ttk.TTkK.FixedWidth)
            wordWrap_value = width_value.value()
            fixedWidth_option.setText(f"Fi&xed width [{wordWrap_value}]")
            wrap_width.close()

        if selection == 'NoWordWrap':
            TTKTextEdit_logcontent.setLineWrapMode(ttk.TTkK.NoWrap)
        if selection == 'WordWrapFitWin':
            TTKTextEdit_logcontent.setLineWrapMode(ttk.TTkK.WidgetWidth)
        if selection == 'WordWrapFixed':
            wrap_width = ttk.TTkWindow(pos=(3, 2), size=(20, 7),
                                       title=ttk.TTkString("Desired width", ttk.TTkColor.ITALIC),
                                       border=True,
                                       layout=ttk.TTkVBoxLayout())
            width_value = ttk.TTkSpinBox(value=wordWrap_value, maximum=250, minimum=80)
            wrap_width.addWidget(width_value)
            apply_button = ttk.TTkButton(text="Apply")
            cancel_button = ttk.TTkButton(text="Cancel")
            wrap_width.addWidget(apply_button)
            wrap_width.addWidget(cancel_button)
            cancel_button.clicked.connect(lambda: wrap_width.close())
            apply_button.clicked.connect(_set_wrap)

            ttk.TTkHelper.overlay(TTKTextEdit_logcontent, wrap_width, 10, 4, True)

    @pyTTkSlot()
    def _parse_json(loaded_file):
        """
        Try to analyse given log to see if it is possible to gather information from json format
        :return:
        """
        used_file = parse_json(loaded_file)

        def transfer_to_show():
            """
            Transfer selected fields to show list
            :return:
            """

            selection = list(fields_found_list.selectedItems())

            if fields_found_list.selectedLabels():
                for s in selection:
                    fields_found_list.removeItem(s)
                    fields_to_show.addItem(str(s.text()))

            fields_found_list.setCurrentRow(0)

        def transfer_to_fields_found():
            """
            Transfer selected fields to show list
            :return:
            """

            selection = list(fields_to_show.selectedItems())

            if fields_to_show.selectedLabels():
                for s in selection:
                    fields_to_show.removeItem(s)
                    fields_found_list.addItem(str(s.text()))

            fields_to_show.setCurrentRow(0)

        def move_item_up():
            """
            Move a field up
            :return:
            """

            if fields_to_show.selectedLabels():
                item = fields_to_show.selectedItems()[0]
                pos = fields_to_show.indexOf(item)
                if pos-1 < 0:
                    return
                fields_to_show.moveItem(pos, pos-1)

        def move_item_down():
            """
            Move a field up
            :return:
            """

            if fields_to_show.selectedLabels():
                item = fields_to_show.selectedItems()[0]
                pos = fields_to_show.indexOf(item)
                if pos+1 > len(fields_to_show.items()):
                    return
                fields_to_show.moveItem(pos, pos+1)

        @pyTTkSlot(ttk.TTkList)
        def reformat_file(ttklist,ok=False):
            """
            Reformat file using aligned fields, this method will read original file to apply any formatting change
            :return:
            """
            global loaded_file, TTKTextEdit_logcontent, current_file
            used_file = load_index(loaded_file)
            used_file.set_name(loaded_file)
            used_file.set('export-file', f"export@{used_file.get('file-name')}")

            fields = []
            for each_selected_field in ttklist.items():
                item = str(each_selected_field.text())
                # Get actual index position from original list:
                fields.append(used_file.get("fields").index(item))

            temp_file_name = f"{used_file.get('file-path')}/{used_file.get_temp_name()}"
            line_count = 0
            if used_file.get('file-format') == 'JSON per line':
                with open(loaded_file, "r") as fh_current_file:
                    with open(temp_file_name, "w") as tmpfile:
                        for each_line in fh_current_file:
                            if max_lines_to_read and  line_count >= max_lines_to_read:
                                break
                            # TTKTextEdit_logcontent.toRawText().split("\n"):
                            tmpfile.write(f"{print_line(each_line, fields, used_file=used_file)}\n")
                            line_count += 1
            if used_file.get('file-format') == 'JSON File':
                with open(loaded_file, "r") as fh_current_file:
                    json_records = json.load(fh_current_file)
                with open(temp_file_name, "w") as tmpfile:
                    for each_line in json_records:
                        if max_lines_to_read and line_count >= max_lines_to_read:
                            break
                        # TTKTextEdit_logcontent.toRawText().split("\n"):
                        tmpfile.write(f"{print_line(each_line, fields, used_file=used_file)}\n")
                        line_count += 1
            original_file = loaded_file
            load_file(temp_file_name, generate_index=False, original_file_info=used_file)
            loaded_file = original_file
            TTkWindow_logs.setTitle(ttk.TTkString(f"Logs reader -- [{original_file}]", ttk.TTkColor.ITALIC))
            print("Modifications done to formatting are temporarily, these are not applied to original file")
            print("If you want these formatting being converted into a file please use File->Export feature...")
            used_file.set("export-format", "**CUSTOM**")
            used_file.save()
            # Remove used temp file...
            used_file.remove_temp_file()
            current_file = used_file

            if ok:
                transformMenu.setEnabled(True)
                fields_found_window.close()

        if used_file.get('fields'):
            listlayout = ttk.TTkGridLayout()
            transformMenu.setEnabled(False)
            fields_found_window = ttk.TTkWindow(size=(70, 18),
                                                title=ttk.TTkString("Fields found", ttk.TTkColor.ITALIC),
                                                border=True,
                                                layout=listlayout)

            frame_fields_found_list = ttk.TTkFrame(layout=ttk.TTkHBoxLayout(),
                                                   border=1,
                                                   title="Available fields",
                                                   maxSize=(40, 15),
                                                   selectionMode=ttk.TTkK.MultiSelection)

            frame_fields_to_show = ttk.TTkFrame(layout=ttk.TTkHBoxLayout(),
                                                border=1,
                                                title="Fields to show",
                                                maxSize=(40, 15))

            frame_middle_buttons = ttk.TTkFrame(layout=ttk.TTkVBoxLayout(), border=0, maxSize=(5, 5))
            frame_sort_buttons = ttk.TTkFrame(layout=ttk.TTkVBoxLayout(), border=0, maxSize=(8, 6))
            button_add = ttk.TTkButton(text=">>")
            button_del = ttk.TTkButton(text="<<")
            button_up = ttk.TTkButton(text="Up")
            button_dn = ttk.TTkButton(text="Down")
            button_ap = ttk.TTkButton(text="Apply")
            button_ok = ttk.TTkButton(text="OK")
            button_cn = ttk.TTkButton(text="Cancel")
            fields_found_list = ttk.TTkList(parent=frame_fields_found_list, dragDropMode=ttk.TTkK.AllowDrag | ttk.TTkK.AllowDrop,
                                            selectionMode=ttk.TTkK.MultiSelection)
            fields_to_show = ttk.TTkList(parent=frame_fields_to_show, dragDropMode=ttk.TTkK.AllowDrag | ttk.TTkK.AllowDrop,
                                         selectionMode=ttk.TTkK.MultiSelection)
            frame_middle_buttons.addWidget(button_add)
            frame_middle_buttons.addWidget(button_del)
            frame_sort_buttons.addWidget(button_up)
            frame_sort_buttons.addWidget(button_dn)

            listlayout.addWidget(frame_fields_found_list, 0, 0, 3, 2)
            listlayout.addWidget(frame_middle_buttons, 1, 2, 1, 1)
            listlayout.addWidget(frame_fields_to_show, 0, 3, 3, 2)
            listlayout.addWidget(frame_sort_buttons, 1, 5, 1, 1)
            listlayout.addWidget(button_ap, 3, 3, 1, 1)
            listlayout.addWidget(button_ok, 3, 4, 1, 1)
            listlayout.addWidget(button_cn, 3, 5, 1, 1)

            # Actions
            button_add.clicked.connect(transfer_to_show)
            button_del.clicked.connect(transfer_to_fields_found)
            button_up.clicked.connect(move_item_up)
            button_dn.clicked.connect(move_item_down)
            button_cn.clicked.connect(lambda: {
                fields_found_window.close(),
                transformMenu.setEnabled(True)
            })
            button_ok.clicked.connect(lambda: reformat_file(fields_to_show, True))
            button_ap.clicked.connect(lambda: reformat_file(fields_to_show))

            for idx, each_field in enumerate(used_file.get("fields")):
                # if we have fields already selected, then they shouldn't showup on fields_found_list
                if used_file.get("show-fields") and idx in used_file.get("show-fields"):
                    continue
                fields_found_list.addItem(each_field)

            if used_file.get("show-fields"):
                for each_field in used_file.get("show-fields"):
                    fields_to_show.addItem(used_file.get("show-fields")[each_field])

            ttk.TTkHelper.overlay(None, fields_found_window, 3, 6, modal=True, toolWindow=True)
        else:
            print("WARNING: Sorry I'm not able to find any json format on this file so"
                  " I was not able to pull any field from it")

    @pyTTkSlot()
    def _export_file(use_file):
        """
        Export actual file, applying transformation to whole file
        :param use_file:
        :return:
        """

        current_file.export()

    def message_window(message, title_window="Message", buttons=None):
        """
        Message window
        :param message:
        :param title_window:
        :param buttons:
        :return:
        """

        layout = ttk.TTkVBoxLayout()
        popupWindow = ttk.TTkWindow(title=title_window,
                                    maxSize=(20, 5),
                                    layout=layout)
        layout.addWidget(ttk.TTkLabel(text=message))
        button_ok = ttk.TTkButton(text="OK")
        button_ok.clicked.connect(lambda: popupWindow.close)
        layout.addWidget(button_ok)
        ttk.TTkHelper.overlay(None, popupWindow, x=5 ,y=5, modal=True)

    fileMenu = TTkWindow_logs.newMenubarTop().addMenu("&File")
    viewMenu = TTkWindow_logs.newMenubarTop().addMenu("&View")
    transformMenu = TTkWindow_logs.newMenubarTop().addMenu("&Transform")
    # File Menu
    fileMenu.addMenu("Open").menuButtonClicked.connect(_show_file_dialog)
    fileMenu.addMenu("Export").menuButtonClicked.connect(lambda: _export_file(current_file))
    fileMenu.addMenu("Close").menuButtonClicked.connect(_close)
    fileMenu.addMenu("Exit").menuButtonClicked.connect(_exit)
    # View Menu
    lineNumber_option = viewMenu.addMenu("Line number-[Enable]")
    lineNumber_option.menuButtonClicked.connect(_line_number)
    viewMenu.addMenu("&File info")

    wordWrap_menu = viewMenu.addMenu("&Word wrap")
    wordWrap_menu.addMenu("&No Word wrap").menuButtonClicked.connect(lambda: _word_wrap_menu("NoWordWrap"))
    wordWrap_menu.addMenu("&Fit Window width").menuButtonClicked.connect(lambda: _word_wrap_menu("WordWrapFitWin"))
    fixedWidth_option = wordWrap_menu.addMenu(f"Fi&xed width [{wordWrap_value}]")
    fixedWidth_option.menuButtonClicked.connect(lambda: _word_wrap_menu("WordWrapFixed"))
    # Transform Menu
    transformParseMenu = transformMenu.addMenu("Parse format")
    transformParseMenu.addMenu("JSON").menuButtonClicked.connect(lambda: _parse_json(loaded_file))
    transformParseMenu.addMenu("CSV")
    transformMenu.addMenu("Analyse file...").menuButtonClicked.connect(lambda: _analyse_file(loaded_file))

    TTkWindow_logs.sizeChanged.connect(_resize_log_content)
    TTKTextEdit_logcontent.setWrapWidth(wordWrap_value)
    TTKTextEdit_logcontent.setLineWrapMode(ttk.TTkK.FixedWidth)
    transformMenu.setEnabled(False)
    viewMenu.setEnabled(False)
    root.layout().addWidget(TTkWindow_logs)
    root.mainloop()


class File:
    attribute = {}

    def __init__(self):
        """

        """
        self.attribute = {}

    def set(self, key, value):
        """
        Set file attribute
        :param key: key name
        :param value: value for key
        :return:
        """
        self.attribute[key] = value

    def get(self, key):
        """
        Return value of give attribute
        :param key: to search for
        :return: stored value for key, None otherwise
        """

        if key in self.attribute:
            return self.attribute[key]

        return None

    def set_name(self, name):
        """

        :param name:
        :return:
        """
        self.attribute["file-name"] = os.path.basename(name)
        path = os.path.dirname(name)
        if path:
            self.attribute["file-path"] = os.path.dirname(name)

    def get_name(self):
        """
        Return file name
        :return:
        """
        return os.path.basename(self.attribute['file-name'])

    def get_path(self):
        """
        Return file directory
        :return:
        """

        if 'file-path' in self.attribute:
            return self.attribute['file-path']
        else:
            return ""

    def set_all_attributes(self, attributes):
        """
        Set all attributes at once
        :param attributes:
        :return:
        """
        self.attribute = attributes

    def get_all_attributes(self):
        """

        :return:
        """
        return self.attribute

    def save(self):
        """
        Save current file attributes into index file
        :return:
        """

        try:
            with open(f"{self.attribute['file-path']}/{self.attribute['file-name']}.jidx", "w") as savefile:
                yaml.safe_dump(self.attribute, savefile)

            print(f"{self.attribute['file-path']}/{self.attribute['file-name']}.jidx support file updated")
        except IOError as io:
            print(level="ERROR", message=f"Unable to save "
                                         f"{self.attribute['file-path']}/{self.attribute['file-name']}.jidx"
                                         f" support file due to {io}")

    def get_temp_name(self, filename=None):
        """
        Save a temporary file
        :return:
        """
        name = None

        if filename:
            name = os.path.basename(filename)
            name = f"temp@{name}.shw"
        else:
            if 'file-name' in self.attribute:
                name = os.path.basename(self.attribute['file-name'])
                name = f"temp@{name}.shw"

        self.set('temp-file', name)
        if not name:
            print("Unable to setup a proper temporarily name, no file name was found")
        return name

    def remove_temp_file(self):
        """
        Remove temporary file
        :return:
        """

        pt = self.get_path()

        if pt:
            full_name = f"{pt}/{self.get('temp-file')}"
        else:
            full_name = self.get('temp-file')

        if 'temp-file' in self.attribute:
            os.remove(full_name)

    def export(self):
        """
        Export current file using selected format by user
        :param format: type of format to be used. JSON field sort, or build-in layout.
        :return:
        """
        global desired_output_format, current_file

        pt = self.get_path()

        if pt:
            full_export_name = f"{pt}/{self.get('export-file')}"
            full_name = f"{pt}/{self.get_name()}"
        else:
            full_export_name = self.get('export-file')
            full_name = self.get_name()

        print(f"** Exporting file: ")
        print(f" * {full_name} as {full_export_name}")
        print(f" * Using format: {self.get('export-format')}")
        if self.get('export-format') == '**CUSTOM**':
            print(" * Using following fields:")
            for ef in self.get('show-fields').values():
                print(f"    * {ef}")
            else:
                print(f" * Using config layout: {self.get('selected-layout')}")

        with open(f"{full_export_name}", "w") as export_file:
            with open(f"{full_name}", "r") as original_file:
                for each_line in original_file:
                    if self.get('export-format') == '**CUSTOM**':
                        cf = self.get("show-fields")
                        strip_line = print_line(each_line.strip('\n'), cf.keys(), current_file)
                        export_file.write(f"{strip_line}\n")
                    else:

                        desired_output_format = layouts[self.get('selected-layout')]
                        strip_line = parse(each_line).strip('\n')
                        export_file.write(f"{strip_line}\n")


class HighlightCode:

    color_library = []

    def __init__(self, description, regex, color):
        """

        :param regex:
        :param color:
        """
        self.description = description
        self.regex = regex
        self.color = color

        HighlightCode.color_library.append(self)

    @staticmethod
    def highlight(txt):
        """

        :return:
        """
        import TermTk as ttk

        ret = txt
        for each_definition in HighlightCode.color_library:
            if m := txt.findall(regexp=each_definition.regex):
                for match in m:
                    ret = ret.setColor(ttk.TTkColor.fg(each_definition.color), match=match)

        return ret


if __name__ == "__main__":
    filepicker_config = {
        "path": ".",
        "size": (120, 35)
    }
    args = None
    current_file = None
    line_number = False
    wordWrap_value = 800
    loaded_file = None
    fields_found = []
    max_lines_to_read = 2500
    TTKTextEdit_logcontent = None
    TTKTextEdit_logging_messages = None

    program_name = os.path.basename(__file__)
    if len(os.path.splitext(program_name)) > 1:
        tmpname = os.path.splitext(program_name)
        program_config = f"{tmpname[0]}.yaml"
    else:
        program_config = f"{program_name}.yaml"

    log_config = None
    config = None
    load_config()
    # Initialization global variable usage
    # Corda 5, expected log format
    expected_log_format = log_config["configuration"]["corda"]["log"]["expect"]
    # log format expected fields:
    # expected_log_fields = log_config["configuration"]["corda"]["log"]["fields"]
    # Get all defined layouts
    layouts = log_config["configuration"]["format"]["layout"]
    # set up default layout
    default_layout = log_config["configuration"]["format"]["default-layout"]
    # # Load required fields
    # fields_of_interest = log_config["configuration"]["log-line-fields"]
    # Desired log output format
    desired_output_format = layouts[default_layout]
    # Collect any required conversion
    conversions = log_config['configuration']['format']['conversions']

    parser = argparse.ArgumentParser()
    parser.add_argument('-l', '--log-file',
                        help='Give actual log file to pre-format')
    parser.add_argument('-o', '--output',
                        help='Give name of file you want to write converted output')
    parser.add_argument('--line-detail', help='A detailed format, which only parses json c5 file into nice-to-see'
                                              ' format, it will include all fields.', action='store_true')
    parser.add_argument('--json-pretty', help='print json with colors to identify key values --experimental--',
                        action='store_true')
    parser.add_argument('--list-conversions', help='Print all available conversions defined', action='store_true')
    parser.add_argument('--run-conversions', help='Will instruct parser to run all conversion found at'
                                                  ' `configuration.format.conversions`', action='store_true')
    parser.add_argument('--list-layouts', help='Will print current supported layouts for output', action='store_true')
    parser.add_argument('--use-layout', help='Specify which layout you want output looks like, use `--list-layout` '
                                             'to list all available layouts.')
    # parser.add_argument('--field-of-interest', help='Will give actual fields that will be scanned from original logs',
    #                     action='store_true')
    parser.add_argument('--show-config', help='Show current used config', action='store_true')
    parser.add_argument('--export-default-config', help='Create a file with default configuration, if this file exist'
                                                        ' program will load config from this file and will overwrite '
                                                        'all internal default, use it to modify default configuration',
                        action='store_true')
    parser.add_argument('--show-line-number', help='Will print line numbers', action='store_true')
    parser.add_argument('--parse-json', help='Will try to parse given file to JSON, and extract data',
                        action='store_true')
    parser.add_argument('--fields', help="a comma separated field numbers to print")
    parser.add_argument('--list-fields', help='If given log has a json format, program will attempt to extract and'
                                              ' show all fields found on it and will generate special "index" file'
                                              ' which will include all these fields for future usages',
                        action='store_true')
    parser.add_argument('--setup', help='An interactive way to setup program default options', action='store_true')
    parser.add_argument('--interactive',
                        '-i', help='Launch an text tui interface to interact with all options',
                        action='store_true')
    parser.add_argument('--skip-pod-name','-p', help='Skip pod name if log has standard corda 5 log format',
                        action='store_true')
    args = parser.parse_args()

    if args.interactive:
        interactive_work()
        exit(0)

    if args.setup:
        setup()
        exit(0)

    if args.list_fields and args.log_file:
        list_log_file_fields()
        exit(0)
    else:
        if args.list_fields and not args.log_file:
            print("This option must be used together with a log file it can't work alone")
            exit(0)

    if args.parse_json and args.log_file:
        parse_json(args.log_file)
        exit(0)

    if args.export_default_config:
        export_default()
        exit(0)

    if args.show_config:
        show_config()
        exit(0)

    if args.list_conversions:
        list_conversions()
        exit(0)

    if args.list_layouts:
        list_layouts()
        exit(0)

    if args.use_layout:
        if args.use_layout not in layouts:
            print(f"{args.use_layout} is not defined, please add it into program configuration to use it, "
                  f"you can use --list-layouts to see which ones are available to use")
            exit(0)

        default_layout = args.use_layout
        # default layout changed, need to re-configurate desired output
        # Desired log output format
        desired_output_format = layouts[default_layout]

    if args.log_file:
        read_file(args.log_file)
    else:
        parser.print_help()
